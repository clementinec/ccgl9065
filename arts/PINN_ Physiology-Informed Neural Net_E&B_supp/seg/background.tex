\subsection{Thermal Comfort Databases and Data Quality Challenges}\label{seg:dbs}
Thermal comfort research has been significantly advanced by the availability of large-scale datasets, such as the ASHRAE Global Thermal Comfort Database II\cite{foldvary_licina_development_2018} and the Chinese Thermal Comfort Dataset\cite{yang2023comparative}. The ASHRAE database II, with over 100,000 entries, and the Chinese dataset, with over 41,000 records, provide various environmental parameters and occupant thermal responses across diverse climates and building types. Recent advances in thermal comfort modeling have demonstrated improved prediction across diverse experimental scenarios\cite{wang2018individual}. However, the reliability of analyses based on these datasets depends critically on data quality, and several systematic issues compromise their utility for robust machine learning applications.

A fundamental challenge lies in missing and inconsistent physiological measurements. Neither database contains direct measurements of core body temperature, skin temperature, or other physiological variables that drive human thermal sensation\cite{wangHumanThermalComfort2024}. Instead, researchers must rely on derived estimates from environmental parameters, introducing uncertainty that propagates through subsequent analyses. This absence of physiological grounding limits models' ability to capture true human thermoregulatory mechanisms and generalize findings across populations.

Environmental measurement inconsistencies further compound these issues. Mean radiant temperature (MRT), a critical parameter for thermal comfort assessment, exemplifies these problems. While thermal comfort calculations require accurate MRT values, many studies oversimplify by assuming MRT equals air temperature, introducing significant errors in thermal assessments. This simplification neglects radiative effects that significantly impact thermal sensation, leading to models that learn from data artifacts rather than true physiological relationships.

Additionally, bias in training data—including subjective biases in thermal sensation scales and sampling bias toward certain demographics—means that even large datasets like ASHRAE II require careful calibration before data mining\cite{xiongCalibratingSubjectiveData2024}. Traditional machine learning approaches\cite{luo_comparing_2020,al-sharifPredictingThermalPreferences2024,wangDimensionAnalysisSubjective2020b} that treat these databases as ground truth are therefore susceptible to learning spurious correlations and overfitting to measurement inconsistencies rather than capturing robust physiological patterns. 


These challenges underscore the need for modeling approaches that can leverage the scale of available data while mitigating the impact of measurement artifacts and missing physiological information. Physics-informed modeling offers a promising solution by embedding known physiological constraints that regularize learning and prevent models from exploiting data quality issues.

% \subsection{Physics-Informed Neural Networks (PINNs)}\label{seg:pinn}
% Physics-Informed Neural Networks has been a fast-developing field for building science over the past few years due to its ability to introduce physics-based modeling into traditional deep learning. PINNs are designed to learn from data while respecting known physical laws and constraints, which makes them particularly useful when multiple governing equations holds when a complex system/phenomena is being observed and documented through data. In studies that are related to the built environment, incorporating physical laws of thermodynamics and heat transfer into PINNs allows them to provide highly accurate predictions in situations where traditional NNs will struggle, with a much smaller amount of computational resources required. This allows PINNs to handle complexities and uncertainties with thermal phenomena such as non-linear heat transfer, convection and radiant heat transfer. 

% Although there has yet to be any real effort in combining neural networks with physics-based constraints, PINNs strengths in accuracy and scalability could therefore push for a paradigm shift as it not only will be accurate in predicting thermal comfort, account for individual variability, but also allows for simulation of complex indoor environments. Given a large enough dataset, a PINN could easily account for various indoor scenarios including mix-mode ventilation systems, radiant cooling/heating systems since the heat exchange processes can be easily expressed via analytical relationships between the occupant and the surrounding environment. That said, noticing the challenges in curating a dataset as large as the ASHRAE database II can be both costly and time-consuming, the first step of this is ideally positioned from leveraging the physiological signals that can be interpreted from the environmental parameters of the combined thermal comfort dataset.

% Based on the state-of-the-art research identified in section~\ref{seg:dbs} and~\ref{seg:pinn}, we identify three interrelated deficiencies in current thermal comfort research/modeling that motivate our proposed study:
% \begin{itemize}
% \item \textbf{Lack of Harmonized Physiological Inputs} Contemporary models either focus on single datasets (ASHRAE II or Chinese) or append ad-hoc demographic features, but none incorporate derived physiological states (e.g., core/skin temperatures) across harmonized databases. This omission limits the ability to capture true human thermoregulatory mechanisms and to generalize findings across populations.

% \item \textbf{Black-Box Architectures with Limited Interpretability} Machine-learning and deep-learning approaches yield high accuracy but operate as opaque predictors, making it difficult to diagnose why a comfort vote was made. Without embedding biophysical knowledge, these models cannot leverage known constraints to build trust or guide feature-selection in sensitive building-control applications.

% \item \textbf{Absence of Energy-Balance and Physiological Constraints} Existing predictive frameworks do not enforce the fundamental energy-conservation laws of human thermoregulation, allowing intermediate outputs to fall outside physiologically realistic ranges. This gap leads to potential overfitting, physiologically implausible predictions, and reduced robustness when deploying models on noisy or extrapolated data.

% \end{itemize}
% Our proposed PINN framework explicitly targets these gaps by unifying data sources, integrating biophysical priors into the model architecture, and enforcing energy-balance constraints—thereby providing a more robust, interpretable, and generalizable solution for thermal comfort prediction.

\subsection{Physics-Informed Neural Networks (PINNs) for Thermal Comfort}\label{seg:pinn}

PINNs represent a transformative approach that directly addresses the data quality and validation challenges identified in thermal comfort research. Unlike conventional neural networks that learn purely from data correlations, PINNs integrate known physical laws and constraints directly into the learning process, providing a solution to the fundamental question raised by data quality concerns: how can we ensure model reliability when training data contains measurement artifacts or synthetic components?

\paragraph{Physiological Variables and Validation Through Physics Constraints} Thermal comfort assessment fundamentally depends on human thermoregulatory responses, specifically core body temperature ($T_{core}$), mean skin temperature ($T_{skin}$), and skin wettedness ($w$). These variables directly influence thermal sensation through established physiological mechanisms: $T_{core}$ reflects the body's metabolic heat production and overall thermal state, $T_{skin}$ governs sensory input to the central nervous system, and $w$ indicates evaporative cooling capacity. However, as noted previously, these critical variables are absent from existing databases, forcing researchers to rely on derived estimates without validation mechanisms.

PINNs address this validation challenge through embedded physiological constraints that act as continuous validation criteria. Rather than requiring external validation datasets with measured physiological data, PINNs enforce known relationships such as energy balance equations and physiological range constraints. For example, human $T_{core}$ must remain within narrow bounds (approximately 36.5-37.5°C) for normal function, while $T_{skin}$ varies within predictable ranges (typically 30-36°C) based on environmental conditions. By penalizing predictions that violate these established physiological principles, the PINN ensures that reconstructed physiological data remains within realistic bounds even when derived from environmental parameters.

\paragraph{Energy Balance as Validation Mechanism} The human body's energy balance provides a fundamental validation constraint that addresses concerns about synthetic data reliability. Under steady-state conditions, metabolic heat production must equal heat loss through convection, radiation, evaporation, and respiration. This relationship, expressed as $Q_{balance} = (M - W) - (Q_{conv} + Q_{rad} + Q_{evap} + Q_{res}) \approx 0$, serves as a physics-based validation criterion that synthetic or reconstructed data must satisfy. Traditional machine learning models cannot leverage this constraint, making them vulnerable to learning from physiologically implausible data combinations. PINNs, by enforcing energy balance through custom loss functions, provide continuous validation that ensures physiological consistency regardless of input data quality.

\paragraph{Regularization Against Data Artifacts} The physics constraints in PINNs function as sophisticated regularizers that prevent models from exploiting measurement artifacts or synthetic data inconsistencies. When training data contains errors—such as oversimplified MRT assumptions or imputed demographic variables—traditional models may learn spurious correlations that appear accurate on training data but fail to generalize. Physics constraints prevent this by ensuring that learned relationships must satisfy fundamental physiological laws, effectively filtering out patterns that contradict established biophysical principles.

Based on these capabilities and the limitations identified in sections~\ref{seg:dbs} and current PINN applications, we identify three critical deficiencies that our approach addresses:

\begin{itemize}
\item \textbf{Lack of Validation for Reconstructed Physiological Data} Existing approaches generate synthetic physiological variables from environmental data without validation mechanisms, raising concerns about reliability. Our PINN framework provides continuous validation through embedded energy balance and physiological range constraints.

\item \textbf{Vulnerability to Data Quality Issues} Traditional models cannot distinguish between measurement artifacts and genuine patterns, leading to unreliable predictions when deployed on new data. Physics constraints act as filters that ensure learned relationships remain physiologically plausible despite input data quality issues.

\item \textbf{Absence of Interpretable Validation Outputs} Black-box models provide no mechanism to assess whether predictions align with known physiological principles. Our PINN produces interpretable intermediate outputs ($T_{core}$, $T_{skin}$, $w$) that can be validated against established physiological ranges and energy balance requirements.
\end{itemize}

Our proposed PINN framework directly addresses these limitations by treating physics constraints not as additional complexity, but as validation mechanisms that ensure model reliability when working with large-scale datasets containing inevitable quality issues.